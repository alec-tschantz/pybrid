{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hybrid.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.2 64-bit ('pybrid': conda)",
      "metadata": {
        "interpreter": {
          "hash": "82ca0910b36e2fe5a005ae0b5da79a0767095f44faeef9b478a9f3cc93cefa3a"
        }
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2-final"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho-Uzn-ZfKJn",
        "outputId": "429098d5-8de1-448c-8539-3a2b7cdd9e5d"
      },
      "source": [
        "# !pip install git+https://github.com/alec-tschantz/pybrid.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2XgNTz5hTkn"
      },
      "source": [
        "import logging\n",
        "\n",
        "import torch\n",
        "\n",
        "from pybrid import utils\n",
        "from pybrid import datasets\n",
        "from pybrid import optim\n",
        "from pybrid.models.hybrid import HybridModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcvB5JhPh7fm"
      },
      "source": [
        "def main(cfg):\n",
        "    cfg = utils.setup_experiment(cfg)\n",
        "\n",
        "    datasets.download_mnist()\n",
        "    train_dataset = datasets.MNIST(\n",
        "        train=True,\n",
        "        scale=cfg.data.label_scale,\n",
        "        size=cfg.data.train_size,\n",
        "        normalize=cfg.data.normalize,\n",
        "    )\n",
        "    test_dataset = datasets.MNIST(\n",
        "        train=False,\n",
        "        scale=cfg.data.label_scale,\n",
        "        size=cfg.data.test_size,\n",
        "        normalize=cfg.data.normalize,\n",
        "    )\n",
        "    train_loader = datasets.get_dataloader(train_dataset, cfg.optim.batch_size)\n",
        "    test_loader = datasets.get_dataloader(test_dataset, cfg.optim.batch_size)\n",
        "    msg = f\"Loaded MNIST ({len(train_loader)} train batches {len(test_loader)} test batches)\"\n",
        "    logging.info(msg)\n",
        "\n",
        "    model = HybridModel(\n",
        "        nodes=cfg.model.nodes,\n",
        "        amort_nodes=cfg.model.amort_nodes,\n",
        "        mu_dt=cfg.infer.mu_dt,\n",
        "        act_fn=utils.get_act_fn(cfg.model.act_fn),\n",
        "        use_bias=cfg.model.use_bias,\n",
        "        kaiming_init=cfg.model.kaiming_init,\n",
        "    )\n",
        "    optimizer = optim.get_optim(\n",
        "        model.params,\n",
        "        cfg.optim.name,\n",
        "        cfg.optim.lr,\n",
        "        amort_lr=cfg.optim.amort_lr,\n",
        "        batch_scale=cfg.optim.batch_scale,\n",
        "        grad_clip=cfg.optim.grad_clip,\n",
        "        weight_decay=cfg.optim.weight_decay,\n",
        "    )\n",
        "    logging.info(f\"Loaded model {model}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        metrics = {\"hybrid_acc\": [], \"pc_acc\": [], \"amort_acc\": []}\n",
        "        for epoch in range(1, cfg.exp.num_epochs + 1):\n",
        "            pc_losses, amort_losses = [], []\n",
        "            logging.info(f\"Train @ epoch {epoch} ({len(train_loader)} batches)\")\n",
        "            \n",
        "            for batch_id, (img_batch, label_batch) in enumerate(train_loader):\n",
        "                model.train_batch(\n",
        "                    img_batch,\n",
        "                    label_batch,\n",
        "                    cfg.infer.num_train_iters,\n",
        "                    fixed_preds=cfg.infer.fixed_preds_train,\n",
        "                    use_amort=cfg.model.train_amortised,\n",
        "                )\n",
        "                optimizer.step(\n",
        "                    curr_epoch=epoch,\n",
        "                    curr_batch=batch_id,\n",
        "                    n_batches=len(train_loader),\n",
        "                    batch_size=img_batch.size(0),\n",
        "                )\n",
        "\n",
        "                pc_loss, amort_loss = model.get_loss()\n",
        "                pc_losses.append(pc_loss)\n",
        "                amort_losses.append(amort_loss)\n",
        "\n",
        "                if batch_id % 100 == 0:\n",
        "                    pc_loss = sum(pc_losses) / (batch_id + 1)\n",
        "                    amort_loss = sum(amort_losses) / (batch_id + 1)\n",
        "                    msg = f\"batch [{batch_id}/{len(train_loader)}]:\"\n",
        "                    msg = msg + f\"pc [{pc_loss:.4f}] amortised [{amort_loss:.4f}]\"\n",
        "                    logging.info(msg)\n",
        "\n",
        "            if epoch % cfg.exp.test_every == 0:\n",
        "                logging.info(f\"Test @ epoch {epoch} ({len(test_loader)} batches)\")\n",
        "                hybrid_acc, pc_acc, amort_acc = 0, 0, 0\n",
        "                for _, (img_batch, label_batch) in enumerate(test_loader):\n",
        "\n",
        "                    label_preds = model.test_batch(\n",
        "                        img_batch, cfg.infer.num_test_iters, fixed_preds=cfg.infer.fixed_preds_test\n",
        "                    )\n",
        "                    hybrid_acc = hybrid_acc + datasets.accuracy(label_preds, label_batch)\n",
        "\n",
        "                    label_preds = model.test_batch(\n",
        "                        img_batch,\n",
        "                        cfg.infer.num_test_iters,\n",
        "                        init_std=cfg.infer.init_std,\n",
        "                        fixed_preds=cfg.infer.fixed_preds_test,\n",
        "                        use_amort=False,\n",
        "                    )\n",
        "                    pc_acc = pc_acc + datasets.accuracy(label_preds, label_batch)\n",
        "\n",
        "                    label_preds = model.forward(img_batch)\n",
        "                    amort_acc = amort_acc + datasets.accuracy(label_preds, label_batch)\n",
        "\n",
        "                hybrid_acc = hybrid_acc / len(test_loader)\n",
        "                pc_acc = pc_acc / len(test_loader)\n",
        "                amort_acc = amort_acc / len(test_loader)\n",
        "                metrics[\"hybrid_acc\"].append(hybrid_acc)\n",
        "                metrics[\"pc_acc\"].append(pc_acc)\n",
        "                metrics[\"amort_acc\"].append(amort_acc)\n",
        "                msg = \"hybrid accuracy: {:.4f} pc accuracy {:.4f} amortised accuracy {:.4f} \"\n",
        "                logging.info(msg.format(hybrid_acc, pc_acc, amort_acc))\n",
        "\n",
        "                _, label_batch = next(iter(test_loader))\n",
        "                img_preds = model.backward(label_batch)\n",
        "                datasets.plot_imgs(img_preds, cfg.exp.img_dir + f\"/{epoch}.png\")\n",
        "\n",
        "            utils.save_json(metrics, cfg.exp.log_dir + \"/metrics.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTwqMpFPiEj5",
        "outputId": "0d85934b-dc3f-48a5-b1e2-62646141b726"
      },
      "source": [
        "cfg = {\n",
        "    \"exp\": {\"log_dir\": \"results/hybrid\", \"seed\": 0, \"num_epochs\": 20, \"test_every\": 1},\n",
        "    \"data\": {\"train_size\": 5000, \"test_size\": 2000, \"label_scale\": 0.94, \"normalize\": True},\n",
        "    \"infer\": {\n",
        "        \"mu_dt\": 0.01,\n",
        "        \"num_train_iters\": 50,\n",
        "        \"num_test_iters\": 200,\n",
        "        \"fixed_preds_train\": False,\n",
        "        \"fixed_preds_test\": False,\n",
        "        \"init_std\": 0.01,\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"nodes\": [10, 500, 500, 784],\n",
        "        \"amort_nodes\": [784, 500, 500, 10],\n",
        "        \"train_amortised\": True,\n",
        "        \"use_bias\": True,\n",
        "        \"kaiming_init\": False,\n",
        "        \"act_fn\": \"tanh\",\n",
        "    },\n",
        "    \"optim\": {\n",
        "        \"name\": \"Adam\",\n",
        "        \"lr\": 1e-4,\n",
        "        \"amort_lr\": 1e-4,\n",
        "        \"batch_size\": 64,\n",
        "        \"batch_scale\": True,\n",
        "        \"grad_clip\": 50,\n",
        "        \"weight_decay\": None,\n",
        "    },\n",
        "}\n",
        "main(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}